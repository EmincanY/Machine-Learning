{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\Emincan\\Desktop\\Playground\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\Emincan\\Desktop\\Playground\\test.csv')\n",
    "sub = pd.read_csv(r'C:\\Users\\Emincan\\Desktop\\Playground\\sample_submission.csv')\n",
    "\n",
    "test_ids = test['id']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('id' , axis =1 , inplace = True)\n",
    "test.drop('id' , axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8) ,dpi=100)\n",
    "\n",
    "sns.heatmap(train.corr(numeric_only=True) , annot = True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score , confusion_matrix, classification_report, mean_absolute_error, mean_squared_error, r2_score , roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV , RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE , ADASYN\n",
    "\n",
    "\n",
    "\n",
    "class fonks:\n",
    "    \"\"\"\n",
    "    Class'ın amacı:\n",
    "    - Sıkça kullanılacak fonksiyonları oluşturmak ve kolayca çağırmak.\n",
    "    - Daha düzenli ve değiştirilebilir bir programlama yapmak.\n",
    "    \"\"\"\n",
    "    \n",
    "    label = 'Fertility'\n",
    "    \n",
    "    def overSample(X , y , tactic = 'smote'):\n",
    "        if tactic == 'smote':\n",
    "            smote = SMOTE()\n",
    "            X_resampled , y_resampled = smote.fit_resample(X , y)\n",
    "            return X_resampled , y_resampled\n",
    "        elif tactic == 'adasyn':\n",
    "            adasyn = ADASYN()\n",
    "            X_resampled , y_resampled = adasyn.fit_resample(X , y)\n",
    "            return X_resampled , y_resampled\n",
    "            \n",
    "    \n",
    "    def trainTest(X , y , test_size = 0.2 , stratify = None):\n",
    "        \"\"\"\n",
    "        Alınan datayı istenen oranda Train & Test şeklinde bölüp X_train , X_test , y_train , y_test adındaki 4 değişken döndürür.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pandas.DataFrame\n",
    "            Train & Test olarak bölünecek veri seti.\n",
    "        label : str, optional\n",
    "            Hedef değişkenin adı, by default 'Knowledge'.\n",
    "        test_size : float, optional\n",
    "            Test veri setinin boyutu, by default 0.2.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            X_train, X_test, y_train, y_test\n",
    "        \"\"\"\n",
    "\n",
    "        if stratify == 'y' :\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=test_size , random_state=53 , stratify=y)\n",
    "        else :\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=test_size , random_state=53)\n",
    "        \n",
    "        return X_train, X_test, y_train,y_test\n",
    "\n",
    "\n",
    "    def simple_scores(y_train, y_train_pred, y_test, y_pred, name='Model' , task = 'reg'):\n",
    "        \"\"\"\n",
    "        Model ismini, Train ve Test'e ait tahmin ve gerçek değerleri alıp, Alınan acc, f1 ve precision skorlarını yazdırır.\n",
    "        Hem Regression hem Classification taskleri için tasarlanmıştır.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_train : pandas.DataFrame\n",
    "            Train verisinin gerçek değerleri.\n",
    "        y_train_pred : pandas.DataFrame\n",
    "            Train verisine ait tahmin değerleri.\n",
    "        y_test : pandas.DataFrame\n",
    "            Test verisinin gerçek değerleri.\n",
    "        y_pred : pandas.DataFrame\n",
    "            Test verisine ait tahmin değerleri.\n",
    "        name : str optional\n",
    "            Tahmini alınan modelin ismi, by default 'Model'.\n",
    "        task : str optional, default 'reg'\n",
    "            Görevin type'ı 'reg' or 'class'\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        print\n",
    "            Train Acc , Train F1 , Train Precision , Test Acc , Test F1 , Test Precision\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        if task == 'class':\n",
    "            print(f'{name} Train Accuracy : {accuracy_score(y_train , y_train_pred)}')\n",
    "            print(f'{name} Train Recall : {recall_score(y_train, y_train_pred, pos_label=1)}')\n",
    "            print(f'{name} Train Precision : {precision_score(y_train , y_train_pred, pos_label=1)}')\n",
    "            print(f'{name} Train F1 : {f1_score(y_train , y_train_pred , pos_label=1)}')\n",
    "            \n",
    "            \n",
    "            print(\"\\n****************\\n\")\n",
    "            \n",
    "            print(f'{name} Test Accuracy : {accuracy_score(y_test , y_pred)}')\n",
    "            print(f'{name} Test Recall : {recall_score(y_test, y_pred, pos_label=1)}')\n",
    "            print(f'{name} Test Precision : {precision_score(y_test , y_pred, pos_label=1)}')\n",
    "            print(f'{name} Test F1 : {f1_score(y_test , y_pred, pos_label=1)}')\n",
    "        elif task == 'reg':\n",
    "            print(f'{name} Train R2 : {r2_score(y_train , y_train_pred)}')\n",
    "            print(f'{name} Train Mae : {mean_absolute_error(y_train, y_train_pred)}')\n",
    "            print(f'{name} Train RMSE : {mean_squared_error(y_train , y_train_pred)**0.5}')\n",
    "            print(f'{name} Train MSE : {mean_squared_error(y_train , y_train_pred)}')\n",
    "            \n",
    "            \n",
    "            print(\"\\n****************\\n\")\n",
    "            \n",
    "            print(f'{name} Test R2 : {r2_score(y_test , y_pred)}')\n",
    "            print(f'{name} Test Mae : {mean_absolute_error(y_test, y_pred)}')\n",
    "            print(f'{name} Test RMSE : {mean_squared_error(y_test , y_pred)**0.5}')\n",
    "            print(f'{name} Test MSE : {mean_squared_error(y_test , y_pred)}')\n",
    "        \n",
    "    def get_r2_score(y_true, y_pred):\n",
    "        return r2_score(y_true,y_pred)\n",
    "    def get_mae_score(y_true, y_pred):\n",
    "        return mean_absolute_error(y_true,y_pred)\n",
    "    def get_rmse_score(y_true, y_pred):\n",
    "        return mean_squared_error(y_true,y_pred)**0.5\n",
    "    def get_mse_score(y_true, y_pred):\n",
    "        return mean_squared_error(y_true,y_pred)\n",
    "        \n",
    "        \n",
    "    def get_acc_score(y_true, y_pred):\n",
    "        return accuracy_score(y_true , y_pred)    \n",
    "    def get_f1_score(y_true, y_pred):\n",
    "        return f1_score(y_true , y_pred , pos_label=1)\n",
    "    \n",
    "    def get_recall(y_true, y_pred):\n",
    "        return recall_score(y_true, y_pred, pos_label=1)\n",
    "    \n",
    "    def get_roc_auc(y_true, y_pred):\n",
    "        return roc_auc_score(y_true, y_pred, pos_label=1)\n",
    "    \n",
    "    \n",
    "    def eval_metric(y_train, y_train_pred, y_test, y_pred, name='Model'):\n",
    "        \"\"\"\n",
    "        Model ismini, Train ve Test'e ait tahmin ve gerçek değerleri alıp, Confusion_matrix ve Classification_report'u yazdırır..\n",
    "        Sadece Classification taskleri için tasarlanmıştır.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_train : pandas.DataFrame\n",
    "            Train verisinin gerçek değerleri.\n",
    "        y_train_pred : pandas.DataFrame\n",
    "            Train verisine ait tahmin değerleri.\n",
    "        y_test : pandas.DataFrame\n",
    "            Test verisinin gerçek değerleri.\n",
    "        y_test_pred : pandas.DataFrame\n",
    "            Test verisine ait tahmin değerleri.\n",
    "        name : str optional\n",
    "            Tahmini alınan modelin ismi, by default 'Model'.\n",
    "        task : str optional, default 'reg'\n",
    "            Görevin type'ı 'reg' or 'class'            \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        print\n",
    "            Train Confusion_matrix , Train Classification_report , Test Confusion_matrix , Test Classification_report\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Test_Set {name}\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print()\n",
    "        print(f\"Train_Set {name}\")\n",
    "        print(confusion_matrix(y_train, y_train_pred))\n",
    "        print(classification_report(y_train, y_train_pred))         \n",
    "        \n",
    "    \n",
    "\n",
    "    def train_test_df(y_train, y_train_pred, y_test, y_pred, name='Model' , task='reg'):\n",
    "        \"\"\"\n",
    "        Model ismini, Train ve Test'e ait tahmin ve gerçek değerleri alıp, Accuracy, Recall, Precision,  yazdırır..\n",
    "        Hem Regression hem Classification taskleri için tasarlanmıştır.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_train : pandas.DataFrame\n",
    "            Train verisinin gerçek değerleri.\n",
    "        y_train_pred : pandas.DataFrame\n",
    "            Train verisine ait tahmin değerleri.\n",
    "        y_test : pandas.DataFrame\n",
    "            Test verisinin gerçek değerleri.\n",
    "        y_test_pred : pandas.DataFrame\n",
    "            Test verisine ait tahmin değerleri.\n",
    "        name : str optional\n",
    "            Tahmini alınan modelin ismi, by default 'Model'.\n",
    "        task : str optional, default 'reg'\n",
    "            Datamızın task'i, 'reg' or 'class'\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        print\n",
    "            Train Accuracy , Train Recall , Train Precision , Train F1 , Test Accuracy , Test Recall , Test Precision , Test F1\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        if task == 'classification':\n",
    "            scores = {name+\"_train\": {\"Accuracy\" : accuracy_score(y_train, y_train_pred),\n",
    "            \"Recall\" : recall_score(y_train, y_train_pred , pos_label=1),\n",
    "            \"Precision\" : precision_score(y_train, y_train_pred , pos_label=1),\n",
    "            \"F1\" : np.sqrt(f1_score(y_train, y_train_pred , pos_label=1))},\n",
    "                    \n",
    "            name+\"_test\": {\"Accuracy\" : accuracy_score(y_test, y_pred),\n",
    "            \"Recall\" : recall_score(y_test, y_pred , pos_label=1),\n",
    "            \"Precision\" : precision_score(y_test, y_pred , pos_label=1),\n",
    "            \"F1\" : np.sqrt(f1_score(y_test, y_pred , pos_label=1))}}\n",
    "            return pd.DataFrame(scores)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if task == 'reg':\n",
    "            \n",
    "            scores = {name+\"_train\": {\"R2\" : r2_score(y_train, y_train_pred),\n",
    "            \"mae\" : mean_absolute_error(y_train, y_train_pred),\n",
    "            \"mse\" : mean_squared_error(y_train, y_train_pred),\n",
    "            \"rmse\" : np.sqrt(mean_squared_error(y_train, y_train_pred))},\n",
    "                    \n",
    "            name+\"_test\": {\"R2\" : r2_score(y_test, y_pred),\n",
    "            \"mae\" : mean_absolute_error(y_test, y_pred),\n",
    "            \"mse\" : mean_squared_error(y_test, y_pred),\n",
    "            \"rmse\" : np.sqrt(mean_squared_error(y_test, y_pred))}}\n",
    "            return pd.DataFrame(scores)\n",
    "\n",
    "    # Fonksiyonun özeti\n",
    "    def summary(df):\n",
    "        # Print the shape of the DataFrame\n",
    "        print(f'data shape: {df.shape}')  \n",
    "        # Create a summary DataFrame\n",
    "        summ = pd.DataFrame(df.dtypes, columns=['data type'])\n",
    "        # Calculate the number of missing values\n",
    "        summ['#missing'] = df.isnull().sum().values \n",
    "        # Calculate the percentage of missing values\n",
    "        summ['%missing'] = df.isnull().sum().values / len(df)* 100\n",
    "        # Calculate the number of unique values\n",
    "        summ['#unique'] = df.nunique().values\n",
    "        # Create a descriptive DataFrame\n",
    "        desc = pd.DataFrame(df.describe(include='all').transpose())\n",
    "        # Add the minimum, maximum, and first three values to the summary DataFrame\n",
    "        summ['min'] = desc['min'].values\n",
    "        summ['max'] = desc['max'].values\n",
    "        summ['first value'] = df.loc[0].values\n",
    "        summ['second value'] = df.loc[1].values\n",
    "        summ['third value'] = df.loc[2].values\n",
    "        \n",
    "        # Return the summary DataFrame\n",
    "        return summ\n",
    "    \n",
    "    def plot_correlation_heatmap(df: pd.core.frame.DataFrame, title_name: str='Train correlation') -> None:\n",
    "        corr = df.corr()  \n",
    "        fig, axes = plt.subplots(figsize=(14, 8))\n",
    "        mask = np.zeros_like(corr)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        sns.heatmap(corr, mask=mask, linewidths=.5, cmap='YlOrRd', annot=True)\n",
    "        plt.title(title_name)\n",
    "        plt.show()\n",
    "\n",
    "    # # plot_correlation_heatmap(original, 'Original Dataset Correlation')\n",
    "    # plot_correlation_heatmap(train, 'Train Dataset Correlation')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Tactic ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \"\"\"\n",
    "    Class'ın amacı:\n",
    "    - Feature engineering aşamasını aç-kapa formatına dönüştürerek bug azaltmak\n",
    "    - Nihai çözümümde bazı featurelar olmasa dahi deneme yapılan feature kapsamını genişletmek/gösterebilmek.\n",
    "    \"\"\"\n",
    "    \n",
    "    target = 'Age'\n",
    "    train_path = r'C:\\Users\\Emincan\\Desktop\\Playground\\train.csv'\n",
    "    submission_path = '/kaggle/input/gdz-elektrik-datathon-2023/sample_submission.csv'\n",
    "    read_from_path = True\n",
    "    \n",
    "    #Hangi dataların kullanılacağına karar verme\n",
    "    sexDummy = True\n",
    "    weightAverage = False\n",
    "    \n",
    "    \n",
    "    #Feature türlerine karar verme\n",
    "    production_lag_features = True\n",
    "    consumption_lag_features = False\n",
    "    diff_pct_features = False\n",
    "    weather_lag_features = True\n",
    "    solar_lag_features = True\n",
    "    rolling_features = False\n",
    "    rolling_shift_features = False\n",
    "    \n",
    "    #Feature parametreleri\n",
    "    nasa_feature_columns =  ['T2M','T2MDEW','T2MWET','QV2M','RH2M','PRECTOTCORR','PS','WS10M','WD10M','WS50M']\n",
    "    meteostat_feature_columns = ['dwpt','rhum','prcp','wdir','wspd','pres','coco']\n",
    "    production_base_columns = ['fueloil','gasOil','blackCoal','lignite','geothermal','naturalGas','river','dammedHydro','lng','biomass','importCoal','asphaltiteCoal','wind','sun','importExport','wasteheat','total']\n",
    "    consumption_base_columns = ['consumption']\n",
    "    weather_lag_range = np.arange(0,51,5)\n",
    "    rolling_range = np.arange(0,48,6)[1:]\n",
    "    roll_types = ['mean','std','min','max']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Tactics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.sexDummy:\n",
    "    train = pd.get_dummies(train, columns=['Sex'])\n",
    "    test = pd.get_dummies(test, columns=['Sex'])\n",
    "\n",
    "if CFG.weightAverage:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonks.summary(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numerical and categorical variables respectively.\n",
    "num_cols = test.select_dtypes(include=['float64']).columns.tolist()\n",
    "cat_cols = test.select_dtypes(include=['object' , 'bool']).columns.tolist()\n",
    "all_features = num_cols + cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the distribution of target variable\n",
    "\n",
    "sns.histplot(train, x=\"Age\", kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check numerical variables' distribution\n",
    "import math\n",
    "\n",
    "features = num_cols\n",
    "n_bins = 50\n",
    "histplot_hyperparams = {\n",
    "    'kde':True,\n",
    "    'alpha':0.4,\n",
    "    'stat':'percent',\n",
    "    'bins':n_bins\n",
    "}\n",
    "\n",
    "columns = features\n",
    "n_cols = 4\n",
    "n_rows = math.ceil(len(columns)/n_cols)\n",
    "fig, ax = plt.subplots(n_rows, n_cols, figsize=(20, n_rows*4))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    plot_axes = [ax[i]]\n",
    "    sns.kdeplot(\n",
    "        train[column], label='Train',\n",
    "        ax=ax[i], color='#9E3F00'\n",
    "    )\n",
    "    \n",
    "    sns.kdeplot(\n",
    "        test[column], label='Test',\n",
    "        ax=ax[i], color='yellow'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # titles\n",
    "    ax[i].set_title(f'{column} Distribution');\n",
    "    ax[i].set_xlabel(None)\n",
    "    \n",
    "    # remove axes to show only one at the end\n",
    "    plot_axes = [ax[i]]\n",
    "    handles = []\n",
    "    labels = []\n",
    "    for plot_ax in plot_axes:\n",
    "        handles += plot_ax.get_legend_handles_labels()[0]\n",
    "        labels += plot_ax.get_legend_handles_labels()[1]\n",
    "        plot_ax.legend().remove()\n",
    "    \n",
    "for i in range(i+1, len(ax)):\n",
    "    ax[i].axis('off')\n",
    "    \n",
    "fig.suptitle(f'Numerical Feature Distributions\\n\\n\\n', ha='center',  fontweight='bold', fontsize=25)\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.96), fontsize=25, ncol=3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# kudos to @jcaliz /  \n",
    "# refer to https://www.kaggle.com/code/sergiosaharovskiy/ps-s3e7-2023-eda-and-submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_count = len(num_cols)\n",
    "n_rows = num_cols_count\n",
    "\n",
    "fig, axs = plt.subplots(n_rows, 2, figsize=(10, n_rows*4))\n",
    "\n",
    "for idx, col in enumerate(num_cols):\n",
    "\n",
    "    # Plot histogram\n",
    "    sns.histplot(data=train, x=col, kde=True, ax=axs[idx, 0], color='blue')\n",
    "    axs[idx, 0].set_title(f'Histogram of {col}')\n",
    "\n",
    "    # Plot boxplot\n",
    "    sns.boxplot(data=train, x=col, ax=axs[idx, 1])\n",
    "    axs[idx, 1].set_title(f'Boxplot of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_distribution(data, column):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(data=data, x=column, color='#9E3F00')\n",
    "    plt.title(f'{column} Distribution')\n",
    "    plt.xlabel(None)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, fontsize=8)\n",
    "    plt.show()\n",
    "# plot categorical variables\n",
    "\n",
    "for col in cat_cols:\n",
    "    plot_categorical_distribution(train, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonks.plot_correlation_heatmap(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "cv_scores = list()\n",
    "importance_xgb = list()\n",
    "preds = list()\n",
    "\n",
    "# Assuming 'train_df' is your DataFrame, and 'Age' is your target column\n",
    "X = train.drop('Age', axis=1)\n",
    "Y = train['Age']\n",
    "\n",
    "# Preprocess categorical columns\n",
    "cat_cols = [] # fill in the list of your categorical variables\n",
    "num_cols = [] # fill in the list of your numerical variables\n",
    "\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype('category')\n",
    "    X[c] = X[c].cat.codes\n",
    "\n",
    "## Running 3-fold CV\n",
    "for i in range(3):\n",
    "    print(f'\\nFold {i+1} CV begins')\n",
    "    skf = KFold(n_splits=3, random_state=np.random.randint(0,999), shuffle=True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        XGB_md = XGBRegressor(tree_method='gpu_hist',\n",
    "                              objective='reg:squarederror',\n",
    "                              colsample_bytree=0.8, \n",
    "                              gamma=0.8, \n",
    "                              learning_rate=0.01, \n",
    "                              max_depth=5, \n",
    "                              min_child_weight=10, \n",
    "                              n_estimators=1500, \n",
    "                              subsample=0.9).fit(X_train, Y_train)\n",
    "        importance_xgb.append(XGB_md.feature_importances_)\n",
    "        \n",
    "        XGB_pred_1 = np.round(XGB_md.predict(X_test))\n",
    "        mae = mean_absolute_error(Y_test, XGB_pred_1)\n",
    "        cv_scores.append(mae)\n",
    "        print(f'Fold {i+1} CV done. MAE: \\033[1;36m{mae:.5f}\\033[0m')\n",
    "\n",
    "scores = np.mean(cv_scores)    \n",
    "print(f'\\nThe average MAE over 3-folds (run 3 times) is: \\033[1;36m{scores:.5f}\\033[0m')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Assuming importance_xgb contains the feature importances from the XGB model\n",
    "# Assuming preds contains the predictions from the XGB model\n",
    "\n",
    "# Create subplots with 1 row and 2 columns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot of actual values vs predicted values\n",
    "axes[0].scatter(Y_test, XGB_pred_1, color='blue', label='Actual', alpha=0.5)\n",
    "axes[0].plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], color='red', alpha=0.5, linewidth=2)\n",
    "axes[0].set_xlabel('Actual Values')\n",
    "axes[0].set_ylabel('Predicted Values')\n",
    "axes[0].set_title('Scatter Plot: Predicted vs. Actual')\n",
    "axes[0].legend(['Reference Line', 'Predicted vs. Actual'])\n",
    "\n",
    "# Feature Importance visualization\n",
    "importance_xgb_avg = np.mean(importance_xgb, axis=0)\n",
    "sorted_feature_indices = np.argsort(importance_xgb_avg)[::-1]\n",
    "sorted_feature_names = [X.columns[i] for i in sorted_feature_indices]\n",
    "sorted_importance = importance_xgb_avg[sorted_feature_indices]\n",
    "\n",
    "color_map = cm.get_cmap('YlOrRd')\n",
    "colors = color_map(np.arange(len(sorted_feature_names)) / len(sorted_feature_names))\n",
    "\n",
    "axes[1].bar(range(len(sorted_feature_names)), sorted_importance, color=colors)\n",
    "axes[1].set_xticks(range(len(sorted_feature_names)))\n",
    "axes[1].set_xticklabels(sorted_feature_names, rotation='vertical')\n",
    "axes[1].set_xlabel('Features')\n",
    "axes[1].set_ylabel('Importance')\n",
    "axes[1].set_title('Feature Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
