{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\Emincan\\Desktop\\Playground\\train.csv')\n",
    "# test = pd.read_csv(r'C:\\Users\\Emincan\\Desktop\\Playground\\test.csv')\n",
    "sub = pd.read_csv(r'C:\\Users\\Emincan\\Desktop\\Playground\\sample_submission.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('id' , axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple preprocessing for categorical variable!\n",
    "# train = pd.get_dummies(train, columns=['Sex'])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "train['Sex'] = le.fit_transform(train['Sex'])\n",
    "\n",
    "train['Sex'] = train['Sex'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8) ,dpi=100)\n",
    "\n",
    "sns.heatmap(train.corr(numeric_only=True) , annot = True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score , confusion_matrix, classification_report, mean_absolute_error, mean_squared_error, r2_score , roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV , RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE , ADASYN\n",
    "\n",
    "\n",
    "\n",
    "class fonks:\n",
    "    \"\"\"\n",
    "    Class'ın amacı:\n",
    "    - Sıkça kullanılacak fonksiyonları oluşturmak ve kolayca çağırmak.\n",
    "    - Daha düzenli ve değiştirilebilir bir programlama yapmak.\n",
    "    \"\"\"\n",
    "    \n",
    "    label = 'Fertility'\n",
    "    \n",
    "    def overSample(X , y , tactic = 'smote'):\n",
    "        if tactic == 'smote':\n",
    "            smote = SMOTE()\n",
    "            X_resampled , y_resampled = smote.fit_resample(X , y)\n",
    "            return X_resampled , y_resampled\n",
    "        elif tactic == 'adasyn':\n",
    "            adasyn = ADASYN()\n",
    "            X_resampled , y_resampled = adasyn.fit_resample(X , y)\n",
    "            return X_resampled , y_resampled\n",
    "            \n",
    "    \n",
    "    def trainTest(X , y , test_size = 0.2 , stratify = None):\n",
    "        \"\"\"\n",
    "        Alınan datayı istenen oranda Train & Test şeklinde bölüp X_train , X_test , y_train , y_test adındaki 4 değişken döndürür.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pandas.DataFrame\n",
    "            Train & Test olarak bölünecek veri seti.\n",
    "        label : str, optional\n",
    "            Hedef değişkenin adı, by default 'Knowledge'.\n",
    "        test_size : float, optional\n",
    "            Test veri setinin boyutu, by default 0.2.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            X_train, X_test, y_train, y_test\n",
    "        \"\"\"\n",
    "\n",
    "        if stratify == 'y' :\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=test_size , random_state=53 , stratify=y)\n",
    "        else :\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=test_size , random_state=53)\n",
    "        \n",
    "        return X_train, X_test, y_train,y_test\n",
    "\n",
    "\n",
    "    def simple_scores(y_train, y_train_pred, y_test, y_pred, name='Model' , task = 'reg'):\n",
    "        \"\"\"\n",
    "        Model ismini, Train ve Test'e ait tahmin ve gerçek değerleri alıp, Alınan acc, f1 ve precision skorlarını yazdırır.\n",
    "        Hem Regression hem Classification taskleri için tasarlanmıştır.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_train : pandas.DataFrame\n",
    "            Train verisinin gerçek değerleri.\n",
    "        y_train_pred : pandas.DataFrame\n",
    "            Train verisine ait tahmin değerleri.\n",
    "        y_test : pandas.DataFrame\n",
    "            Test verisinin gerçek değerleri.\n",
    "        y_pred : pandas.DataFrame\n",
    "            Test verisine ait tahmin değerleri.\n",
    "        name : str optional\n",
    "            Tahmini alınan modelin ismi, by default 'Model'.\n",
    "        task : str optional, default 'reg'\n",
    "            Görevin type'ı 'reg' or 'class'\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        print\n",
    "            Train Acc , Train F1 , Train Precision , Test Acc , Test F1 , Test Precision\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        if task == 'class':\n",
    "            print(f'{name} Train Accuracy : {accuracy_score(y_train , y_train_pred)}')\n",
    "            print(f'{name} Train Recall : {recall_score(y_train, y_train_pred, pos_label=1)}')\n",
    "            print(f'{name} Train Precision : {precision_score(y_train , y_train_pred, pos_label=1)}')\n",
    "            print(f'{name} Train F1 : {f1_score(y_train , y_train_pred , pos_label=1)}')\n",
    "            \n",
    "            \n",
    "            print(\"\\n****************\\n\")\n",
    "            \n",
    "            print(f'{name} Test Accuracy : {accuracy_score(y_test , y_pred)}')\n",
    "            print(f'{name} Test Recall : {recall_score(y_test, y_pred, pos_label=1)}')\n",
    "            print(f'{name} Test Precision : {precision_score(y_test , y_pred, pos_label=1)}')\n",
    "            print(f'{name} Test F1 : {f1_score(y_test , y_pred, pos_label=1)}')\n",
    "        elif task == 'reg':\n",
    "            print(f'{name} Train R2 : {r2_score(y_train , y_train_pred)}')\n",
    "            print(f'{name} Train Mae : {mean_absolute_error(y_train, y_train_pred)}')\n",
    "            print(f'{name} Train RMSE : {mean_squared_error(y_train , y_train_pred)**0.5}')\n",
    "            print(f'{name} Train MSE : {mean_squared_error(y_train , y_train_pred)}')\n",
    "            \n",
    "            \n",
    "            print(\"\\n****************\\n\")\n",
    "            \n",
    "            print(f'{name} Test R2 : {r2_score(y_test , y_pred)}')\n",
    "            print(f'{name} Test Mae : {mean_absolute_error(y_test, y_pred)}')\n",
    "            print(f'{name} Test RMSE : {mean_squared_error(y_test , y_pred)**0.5}')\n",
    "            print(f'{name} Test MSE : {mean_squared_error(y_test , y_pred)}')\n",
    "        \n",
    "    def get_r2_score(y_true, y_pred):\n",
    "        return r2_score(y_true,y_pred)\n",
    "    def get_mae_score(y_true, y_pred):\n",
    "        return mean_absolute_error(y_true,y_pred)\n",
    "    def get_rmse_score(y_true, y_pred):\n",
    "        return mean_squared_error(y_true,y_pred)**0.5\n",
    "    def get_mse_score(y_true, y_pred):\n",
    "        return mean_squared_error(y_true,y_pred)\n",
    "        \n",
    "        \n",
    "    def get_acc_score(y_true, y_pred):\n",
    "        return accuracy_score(y_true , y_pred)    \n",
    "    def get_f1_score(y_true, y_pred):\n",
    "        return f1_score(y_true , y_pred , pos_label=1)\n",
    "    \n",
    "    def get_recall(y_true, y_pred):\n",
    "        return recall_score(y_true, y_pred, pos_label=1)\n",
    "    \n",
    "    def get_roc_auc(y_true, y_pred):\n",
    "        return roc_auc_score(y_true, y_pred, pos_label=1)\n",
    "    \n",
    "    \n",
    "    def eval_metric(y_train, y_train_pred, y_test, y_pred, name='Model'):\n",
    "        \"\"\"\n",
    "        Model ismini, Train ve Test'e ait tahmin ve gerçek değerleri alıp, Confusion_matrix ve Classification_report'u yazdırır..\n",
    "        Sadece Classification taskleri için tasarlanmıştır.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_train : pandas.DataFrame\n",
    "            Train verisinin gerçek değerleri.\n",
    "        y_train_pred : pandas.DataFrame\n",
    "            Train verisine ait tahmin değerleri.\n",
    "        y_test : pandas.DataFrame\n",
    "            Test verisinin gerçek değerleri.\n",
    "        y_test_pred : pandas.DataFrame\n",
    "            Test verisine ait tahmin değerleri.\n",
    "        name : str optional\n",
    "            Tahmini alınan modelin ismi, by default 'Model'.\n",
    "        task : str optional, default 'reg'\n",
    "            Görevin type'ı 'reg' or 'class'            \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        print\n",
    "            Train Confusion_matrix , Train Classification_report , Test Confusion_matrix , Test Classification_report\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Test_Set {name}\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print()\n",
    "        print(f\"Train_Set {name}\")\n",
    "        print(confusion_matrix(y_train, y_train_pred))\n",
    "        print(classification_report(y_train, y_train_pred))         \n",
    "        \n",
    "    \n",
    "\n",
    "    def train_test_df(y_train, y_train_pred, y_test, y_pred, name='Model' , task='reg'):\n",
    "        \"\"\"\n",
    "        Model ismini, Train ve Test'e ait tahmin ve gerçek değerleri alıp, Accuracy, Recall, Precision,  yazdırır..\n",
    "        Hem Regression hem Classification taskleri için tasarlanmıştır.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_train : pandas.DataFrame\n",
    "            Train verisinin gerçek değerleri.\n",
    "        y_train_pred : pandas.DataFrame\n",
    "            Train verisine ait tahmin değerleri.\n",
    "        y_test : pandas.DataFrame\n",
    "            Test verisinin gerçek değerleri.\n",
    "        y_test_pred : pandas.DataFrame\n",
    "            Test verisine ait tahmin değerleri.\n",
    "        name : str optional\n",
    "            Tahmini alınan modelin ismi, by default 'Model'.\n",
    "        task : str optional, default 'reg'\n",
    "            Datamızın task'i, 'reg' or 'class'\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        print\n",
    "            Train Accuracy , Train Recall , Train Precision , Train F1 , Test Accuracy , Test Recall , Test Precision , Test F1\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        if task == 'classification':\n",
    "            scores = {name+\"_train\": {\"Accuracy\" : accuracy_score(y_train, y_train_pred),\n",
    "            \"Recall\" : recall_score(y_train, y_train_pred , pos_label=1),\n",
    "            \"Precision\" : precision_score(y_train, y_train_pred , pos_label=1),\n",
    "            \"F1\" : np.sqrt(f1_score(y_train, y_train_pred , pos_label=1))},\n",
    "                    \n",
    "            name+\"_test\": {\"Accuracy\" : accuracy_score(y_test, y_pred),\n",
    "            \"Recall\" : recall_score(y_test, y_pred , pos_label=1),\n",
    "            \"Precision\" : precision_score(y_test, y_pred , pos_label=1),\n",
    "            \"F1\" : np.sqrt(f1_score(y_test, y_pred , pos_label=1))}}\n",
    "            return pd.DataFrame(scores)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if task == 'reg':\n",
    "            \n",
    "            scores = {name+\"_train\": {\"R2\" : r2_score(y_train, y_train_pred),\n",
    "            \"mae\" : mean_absolute_error(y_train, y_train_pred),\n",
    "            \"mse\" : mean_squared_error(y_train, y_train_pred),\n",
    "            \"rmse\" : np.sqrt(mean_squared_error(y_train, y_train_pred))},\n",
    "                    \n",
    "            name+\"_test\": {\"R2\" : r2_score(y_test, y_pred),\n",
    "            \"mae\" : mean_absolute_error(y_test, y_pred),\n",
    "            \"mse\" : mean_squared_error(y_test, y_pred),\n",
    "            \"rmse\" : np.sqrt(mean_squared_error(y_test, y_pred))}}\n",
    "            return pd.DataFrame(scores)\n",
    "\n",
    "    # Fonksiyonun özeti\n",
    "    def summary(df):\n",
    "        # Print the shape of the DataFrame\n",
    "        print(f'data shape: {df.shape}')  \n",
    "        # Create a summary DataFrame\n",
    "        summ = pd.DataFrame(df.dtypes, columns=['data type'])\n",
    "        # Calculate the number of missing values\n",
    "        summ['#missing'] = df.isnull().sum().values \n",
    "        # Calculate the percentage of missing values\n",
    "        summ['%missing'] = df.isnull().sum().values / len(df)* 100\n",
    "        # Calculate the number of unique values\n",
    "        summ['#unique'] = df.nunique().values\n",
    "        # Create a descriptive DataFrame\n",
    "        desc = pd.DataFrame(df.describe(include='all').transpose())\n",
    "        # Add the minimum, maximum, and first three values to the summary DataFrame\n",
    "        summ['min'] = desc['min'].values\n",
    "        summ['max'] = desc['max'].values\n",
    "        summ['first value'] = df.loc[0].values\n",
    "        summ['second value'] = df.loc[1].values\n",
    "        summ['third value'] = df.loc[2].values\n",
    "        \n",
    "        # Return the summary DataFrame\n",
    "        return summ\n",
    "    \n",
    "    def plot_correlation_heatmap(df: pd.core.frame.DataFrame, title_name: str='Train correlation') -> None:\n",
    "        corr = df.corr()  \n",
    "        fig, axes = plt.subplots(figsize=(14, 8))\n",
    "        mask = np.zeros_like(corr)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        sns.heatmap(corr, mask=mask, linewidths=.5, cmap='YlOrRd', annot=True)\n",
    "        plt.title(title_name)\n",
    "        plt.show()\n",
    "\n",
    "    # # plot_correlation_heatmap(original, 'Original Dataset Correlation')\n",
    "    # plot_correlation_heatmap(train, 'Train Dataset Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonks.plot_correlation_heatmap(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categoric nan Fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def nanFiller(df, label , nan_cols=None):\n",
    "    if nan_cols is None:\n",
    "        # 'thal' sütunundaki eksik değerleri tahmin etmek için kullanacağımız veri setini ayarlayın\n",
    "        train_data = df.dropna(subset=[label])  # 'thal' sütununda eksik değerleri içermeyen gözlemleri kullanın\n",
    "\n",
    "        # Özellikleri ve hedef sütunu belirleyin\n",
    "        features = train_data.drop(label, axis=1)\n",
    "        target = train_data[label]\n",
    "\n",
    "        # Modeli oluşturun ve eğitin\n",
    "        model = GradientBoostingClassifier()\n",
    "        model.fit(features, target)\n",
    "\n",
    "        # 'thal' sütunundaki eksik değerleri tahmin etmek için kullanacağımız veri setini ayarlayın\n",
    "        test_data = df[df[label].isnull()].drop(label, axis=1)\n",
    "\n",
    "        # 'thal' sütunundaki eksik değerleri tahmin edin\n",
    "        predictions = model.predict(test_data)\n",
    "\n",
    "        # 'thal' sütunundaki eksik değerleri tahmin edilen değerlerle doldurun\n",
    "        df.loc[df[label].isnull(), label] = predictions\n",
    "\n",
    "    elif nan_cols is not None:\n",
    "        # 'ca' sütunundaki eksik değerleri tahmin etmek için kullanacağımız veri setini ayarlayın\n",
    "        train_data = df.dropna(subset=[label])  # 'ca' sütununda eksik değerleri içermeyen gözlemleri kullanın\n",
    "\n",
    "        # Özellikleri ve hedef sütunu belirleyin\n",
    "        features = train_data.drop(nan_cols + [label], axis=1)\n",
    "        target = train_data[label]\n",
    "\n",
    "        # Modeli oluşturun ve eğitin\n",
    "        model = GradientBoostingClassifier()\n",
    "        model.fit(features, target)\n",
    "\n",
    "        # Tahmin edilecek veri setini oluşturun\n",
    "        test_data = df[df[label].isnull()].drop(nan_cols + [label], axis=1)\n",
    "\n",
    "        # 'ca' sütunundaki eksik değerleri tahmin edin\n",
    "        predictions = model.predict(test_data)\n",
    "\n",
    "        # 'ca' sütunundaki eksik değerleri tahmin edilen değerlerle doldurun\n",
    "        df.loc[df[label].isnull(), label] = predictions\n",
    "\n",
    "    # Sonuçları döndürün\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('Age' , axis = 1)\n",
    "y = train['Age']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OverSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oversized , y_oversized = fonks.overSample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oversized = nanFiller(X_oversized , 'Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oversized.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oversized.value_counts(dropna=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train | Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = fonks.trainTest(X_oversized , y_oversized , test_size= 0.2 )\n",
    "\n",
    "# X_train , X_test , y_train , y_test = fonks.trainTest(X , y , test_size= 0.2 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train , y_train)\n",
    "\n",
    "lr_train_pred = np.round(lr.predict(X_train))\n",
    "lr_pred = np.round(lr.predict(X_test))\n",
    "\n",
    "fonks.simple_scores(y_train, lr_train_pred , y_test , lr_pred , 'LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_r2 = fonks.get_r2_score(y_test , lr_pred)\n",
    "lr_mae = fonks.get_mae_score(y_test , lr_pred)\n",
    "lr_rmse = fonks.get_rmse_score(y_test , lr_pred)\n",
    "# nb_rocauc = fonks.get_roc_auc(y_test , nb_pred , \"NB\")\n",
    "# nb_rocauc = roc_auc_score(y_test, nb_pred, multi_class='ovo')\n",
    "\n",
    "lr_df = fonks.train_test_df(y_train, lr_train_pred , y_test , lr_pred , 'LR')\n",
    "lr_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "rdg_grid = RidgeCV(alphas=np.arange(0.001,100,1) , cv = 5)\n",
    "\n",
    "rdg_grid.fit(X_train , y_train)\n",
    "\n",
    "print(f\"Ridge Best Score : {rdg_grid.best_score_}\")\n",
    "print(f\"Ridge Best Alpha : {rdg_grid.alpha_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "rdg = Ridge(alpha = 4)\n",
    "\n",
    "rdg.fit(X_train , y_train)\n",
    "\n",
    "rdg_train_pred = np.round(rdg.predict(X_train))\n",
    "rdg_pred = np.round(rdg.predict(X_test))\n",
    "\n",
    "fonks.simple_scores(y_train, rdg_train_pred , y_test , rdg_pred , 'Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_r2 = fonks.get_r2_score(y_test , rdg_pred)\n",
    "rdg_mae = fonks.get_mae_score(y_test , rdg_pred)\n",
    "rdg_rmse = fonks.get_rmse_score(y_test , rdg_pred)\n",
    "# nb_rocauc = fonks.get_roc_auc(y_test , nb_pred , \"NB\")\n",
    "# nb_rocauc = roc_auc_score(y_test, nb_pred, multi_class='ovo')\n",
    "\n",
    "rdg_df = fonks.train_test_df(y_train, rdg_train_pred , y_test , rdg_pred , 'Ridge')\n",
    "all_df = pd.concat([lr_df , rdg_df] , axis = 1)\n",
    "all_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "las_grid = LassoCV(alphas=np.arange(0.001,100,1) , cv = 5)\n",
    "\n",
    "las_grid.fit(X_train , y_train)\n",
    "\n",
    "# print(f\"Lasso Best Score : {las_grid.best_score_}\")\n",
    "print(f\"Lasso Best Alpha : {las_grid.alpha_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.001 is too low for C value. So Lasso is not good model for that dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import dpctl\n",
    "from sklearnex import patch_sklearn, config_context , unpatch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "\n",
    "with config_context(target_offload = 'gpu:0'):\n",
    "    svr_base = SVR()\n",
    "\n",
    "    # params = {'kernel' : ['linear' , 'poly' , 'rbf' ] , 'degree' : [2,3] , 'gamma' : ['scale' , 'auto'] , 'C' : np.arange(0.01,100,10) }\n",
    "    \n",
    "    params = {'kernel' : ['rbf' ] , 'gamma' : ['scale'] , 'C' : [500,600,700,800]}\n",
    "\n",
    "    svr_grid = GridSearchCV(svr_base , params , scoring='neg_mean_absolute_error' , cv = 3)\n",
    "    svr_grid.fit(X_train , y_train)\n",
    "\n",
    "print(f'Best parameters: {svr_grid.best_params_}')\n",
    "print(f'Best score: {svr_grid.best_score_:.2f}')\n",
    "\n",
    "unpatch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR(kernel = 'rbf' , C=500 , gamma='scale')\n",
    "# svr = svr_grid.best_estimator_\n",
    "svr.fit(X_train , y_train)\n",
    "\n",
    "svr_train_pred = np.round(svr.predict(X_train))\n",
    "svr_pred = np.round(svr.predict(X_test))\n",
    "\n",
    "fonks.simple_scores(y_train, svr_train_pred , y_test , svr_pred , 'SVR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_r2 = fonks.get_r2_score(y_test , svr_pred)\n",
    "svr_mae = fonks.get_mae_score(y_test , svr_pred)\n",
    "svr_rmse = fonks.get_rmse_score(y_test , svr_pred)\n",
    "\n",
    "svr_df = fonks.train_test_df(y_train, svr_train_pred , y_test , svr_pred , 'SVR')\n",
    "all_df = pd.concat([all_df , svr_df] , axis = 1)\n",
    "all_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import dpctl\n",
    "from sklearnex import patch_sklearn, config_context , unpatch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "\n",
    "with config_context(target_offload = 'gpu:0'):\n",
    "    dt_base = DecisionTreeRegressor(random_state= 53)\n",
    "\n",
    "    params = {'max_depth' : np.arange(2,9) , 'min_samples_split' : np.arange(2,5)}\n",
    "\n",
    "    dt_grid = GridSearchCV(dt_base , params , cv = 3 , scoring= 'neg_mean_absolute_error' )\n",
    "    dt_grid.fit(X_train , y_train)\n",
    "\n",
    "print(f\"DT Best Params is : {dt_grid.best_params_}\")\n",
    "print(f\"DT Best Score is : {dt_grid.best_score_}\")\n",
    "\n",
    "unpatch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=8 , min_samples_split=3 , random_state= 53)\n",
    "dt.fit(X_train , y_train)\n",
    "\n",
    "dt_train_pred = np.round(dt.predict(X_train))\n",
    "dt_pred = np.round(dt.predict(X_test))\n",
    "\n",
    "fonks.simple_scores(y_train, dt_train_pred , y_test , dt_pred , 'DT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_r2 = fonks.get_r2_score(y_test , dt_pred)\n",
    "dt_mae = fonks.get_mae_score(y_test , dt_pred)\n",
    "dt_rmse = fonks.get_rmse_score(y_test , dt_pred)\n",
    "\n",
    "dt_df = fonks.train_test_df(y_train, dt_train_pred , y_test , dt_pred , 'DT')\n",
    "all_df = pd.concat([all_df , dt_df] , axis = 1)\n",
    "all_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import dpctl\n",
    "from sklearnex import patch_sklearn, config_context , unpatch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "\n",
    "with config_context(target_offload = 'gpu:0'):\n",
    "    rf_base = RandomForestRegressor()\n",
    "\n",
    "    params = {'n_estimators' : np.arange(100,600,100) , 'max_depth' : np.append(np.arange(2,8) , None) , 'max_features' : np.append(np.arange(2,6) , None) , 'min_samples_split' : [2,3]}\n",
    "\n",
    "    rf_grid = GridSearchCV(rf_base , params , scoring= 'neg_mean_absolute_error' , cv = 3)\n",
    "    rf_grid.fit(X_train , y_train)\n",
    "\n",
    "print(f\"RF Best Params is : {rf_grid.best_params_}\")\n",
    "print(f\"RF Best Score is : {rf_grid.best_score_}\")\n",
    "\n",
    "unpatch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# rf = RandomForestRegressor(n_estimators = 230 , max_depth=6 , min_samples_split=2 , max_features=5)\n",
    "# rf = RandomForestRegressor(n_estimators = 500 , max_depth=7 , min_samples_split=2 , max_features=None)\n",
    "rf = rf_grid.best_estimator_\n",
    "rf.fit(X_train , y_train)\n",
    "\n",
    "rf_train_pred = rf.predict(X_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "fonks.simple_scores(y_train, rf_train_pred , y_test , rf_pred , 'RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_r2 = fonks.get_r2_score(y_test , rf_pred)\n",
    "rf_mae = fonks.get_mae_score(y_test , rf_pred)\n",
    "rf_rmse = fonks.get_rmse_score(y_test , rf_pred)\n",
    "\n",
    "rf_df = fonks.train_test_df(y_train, rf_train_pred , y_test , rf_pred , 'RF')\n",
    "all_df = pd.concat([all_df , rf_df] , axis = 1)\n",
    "all_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "patch_sklearn()\n",
    "\n",
    "with config_context(target_offload = 'gpu:0'):\n",
    "    gb_base = GradientBoostingRegressor()\n",
    "\n",
    "    params = {'n_estimators' : np.arange(100,600,100) , 'learning_rate' : [0.01,0.1,1] , 'subsample' : [0.8 , 1] , 'max_depth' : np.arange(2,7)}\n",
    "\n",
    "    gb_grid = GridSearchCV(gb_base , params , scoring= 'neg_mean_absolute_error' , cv = 3)\n",
    "    gb_grid.fit(X_train , y_train)\n",
    "\n",
    "print(f\"GB Best Params is : {gb_grid.best_params_}\")\n",
    "print(f\"GB Best Score is : {gb_grid.best_score_}\")\n",
    "\n",
    "unpatch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# gb = GradientBoostingRegressor(n_estimators= 240 , max_depth=10 , learning_rate= 0.01 , subsample= 0.8 )\n",
    "# gb = GradientBoostingRegressor(n_estimators= 500 , max_depth=6 , learning_rate= 0.01 , subsample= 0.8 )\n",
    "gb = gb_grid.best_estimator_\n",
    "gb.fit(X_train , y_train)\n",
    "\n",
    "gb_train_pred = gb.predict(X_train)\n",
    "gb_pred = gb.predict(X_test)\n",
    "\n",
    "fonks.simple_scores(y_train, gb_train_pred , y_test , gb_pred , 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_r2 = fonks.get_r2_score(y_test , gb_pred)\n",
    "gb_mae = fonks.get_mae_score(y_test , gb_pred)\n",
    "gb_rmse = fonks.get_rmse_score(y_test , gb_pred)\n",
    "\n",
    "gb_df = fonks.train_test_df(y_train, gb_train_pred , y_test , gb_pred , 'GB')\n",
    "all_df = pd.concat([all_df , gb_df] , axis = 1)\n",
    "all_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "patch_sklearn()\n",
    "\n",
    "with config_context(target_offload = 'gpu:0'):\n",
    "    xgb_base = XGBRegressor(tree_method = 'gpu_hist')\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [100, 150 , 200, 300 , 400 , 500, 600],\n",
    "        'max_depth': [3, 4, 5, 6 , 7],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'gamma': [0, 0.1, 0.2],\n",
    "        'subsample': [0.7, 0.8, 0.9],\n",
    "        'colsample_bytree': [0.6, 0.7, 0.8],\n",
    "        'reg_alpha': [0, 0.01, 0.05],\n",
    "        'reg_lambda': [0, 0.01, 0.05],\n",
    "    }\n",
    "\n",
    "    params2 = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "        'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'gamma': [0, 1, 5, 10],\n",
    "        'min_child_weight': [1, 3, 5, 7],\n",
    "        'scale_pos_weight': [1, 2, 3, 4, 5]\n",
    "    }\n",
    "\n",
    "    xgb_rnd = RandomizedSearchCV(xgb_base , params , scoring= 'neg_mean_absolute_error' , cv = 3 , n_iter= 150)\n",
    "    xgb_rnd.fit(X_train , y_train)\n",
    "\n",
    "print(f\"XGB Best Params is : {xgb_rnd.best_params_}\")\n",
    "print(f\"XGB Best Score is : {xgb_rnd.best_score_}\")\n",
    "\n",
    "unpatch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# xgb = XGBRegressor(n_estimators = 500 , min_child_weight = 5 , max_depth = 3 , learning_rate = 0.1 , gamma = 0, colsample_bytree = 0.7 , subsample= 0.7 , reg_alpha = 0.05 , reg_lambda=0.01)\n",
    "# xgb = XGBRegressor(n_estimators = 400 , min_child_weight = 5 , max_depth = 8 , learning_rate = 0.01 , gamma = 0.1 , colsample_bytree = 0.8 , subsample = 0.9 , reglambda = 0 , reg_alpha = 0.05)\n",
    "xgb = xgb_rnd.best_estimator_\n",
    "xgb.fit(X_train , y_train)\n",
    "\n",
    "xgb_train_pred = xgb.predict(X_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "fonks.simple_scores(y_train, xgb_train_pred , y_test , xgb_pred , 'XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_r2 = fonks.get_r2_score(y_test , xgb_pred)\n",
    "xgb_mae = fonks.get_mae_score(y_test , xgb_pred)\n",
    "xgb_rmse = fonks.get_rmse_score(y_test , xgb_pred)\n",
    "\n",
    "xgb_df = fonks.train_test_df(y_train, xgb_train_pred , y_test , xgb_pred , 'XGB')\n",
    "all_df = pd.concat([all_df , xgb_df] , axis = 1)\n",
    "all_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "patch_sklearn()\n",
    "\n",
    "with config_context(target_offload='gpu:0'):\n",
    "        lgb_base = LGBMRegressor(device = 'gpu')\n",
    "\n",
    "        params = {\n",
    "                'n_estimators': [100, 200, 300 , 400 , 500 , 600],\n",
    "                'max_depth': [3, 5, 7 , 6 , 7, 8],\n",
    "                'learning_rate': [1,0.1,0.01],\n",
    "                'subsample': [0.7,0.8, 0.9, 1.0],\n",
    "                'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "                }\n",
    "\n",
    "        lgb_rnd = RandomizedSearchCV(lgb_base , params , scoring='neg_mean_absolute_error' , cv = 3,  n_iter= 150)\n",
    "        lgb_rnd.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(f'Best parameters: {lgb_rnd.best_params_}')\n",
    "print(f'Best score: {lgb_rnd.best_score_:.2f}')\n",
    "\n",
    "unpatch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# lgb = LGBMRegressor(n_estimators= 100 , learning_rate = 0.1 , max_depth = 6 , subsample = 0.9 , colsample_bytree = 1)\n",
    "# lgb = LGBMRegressor(n_estimators= 100 , learning_rate = 0.1 , max_depth = 8 , subsample = 0.8 , colsample_bytree = 0.8)\n",
    "lgb = lgb_rnd.best_estimator_\n",
    "lgb.fit(X_train , y_train)\n",
    "\n",
    "lgb_train_pred = lgb.predict(X_train)\n",
    "lgb_pred = lgb.predict(X_test)\n",
    "\n",
    "fonks.simple_scores(y_train, lgb_train_pred , y_test , lgb_pred , 'LGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_r2 = fonks.get_r2_score(y_test , lgb_pred)\n",
    "lgb_mae = fonks.get_mae_score(y_test , lgb_pred)\n",
    "lgb_rmse = fonks.get_rmse_score(y_test , lgb_pred)\n",
    "\n",
    "lgb_df = fonks.train_test_df(y_train, xgb_train_pred , y_test , lgb_pred , 'LGB')\n",
    "all_df = pd.concat([all_df , lgb_df] , axis = 1)\n",
    "all_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': 0.03,\n",
    "          'objective':'MAE',\n",
    "          'depth': 6,\n",
    "          'early_stopping_rounds':1000,\n",
    "          'iterations': 10000,\n",
    "          'use_best_model': True,\n",
    "          'eval_metric': \"RMSE\",\n",
    "          'random_state': 986,\n",
    "          'allow_writing_files': False,\n",
    "          'thread_count':24\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['X1 transaction date'] = X_train['X1 transaction date'].astype(int).astype('category')\n",
    "# X_test['X1 transaction date'] = X_test['X1 transaction date'].astype(int).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cb = CatBoostRegressor(**params,\n",
    "                       cat_features= ['Sex_F' , 'Sex_I' , 'Sex_M']\n",
    "                        )\n",
    "cb.fit(X_train,y_train,\n",
    "        eval_set=[(X_test,y_test)],\n",
    "        verbose=500)\n",
    "\n",
    "cb_train_pred = np.round(cb.predict(X_train))\n",
    "cb_pred = np.round(cb.predict(X_test))\n",
    "\n",
    "fonks.simple_scores(y_train, cb_train_pred , y_test , cb_pred , 'CB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_r2 = fonks.get_r2_score(y_test , cb_pred)\n",
    "cb_mae = fonks.get_mae_score(y_test , cb_pred)\n",
    "cb_rmse = fonks.get_rmse_score(y_test , cb_pred)\n",
    "\n",
    "cb_df = fonks.train_test_df(y_train, cb_train_pred , y_test , cb_pred , 'CB')\n",
    "all_df = pd.concat([all_df , cb_df] , axis = 1)\n",
    "all_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "model_train_pred = model.predict(X_train)\n",
    "model_pred = model.predict(X_test)\n",
    "\n",
    "fonks.simple_scores(y_train, model_train_pred , y_test , model_pred , 'Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameWeight_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differentWeight_preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Same Weight Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameWeight_preds = np.round((cb_pred + lgb_pred + xgb_pred + gb_pred + rf_pred + svr_pred) / 6)\n",
    "\n",
    "sameWeight_r2 = fonks.get_r2_score(y_test , sameWeight_preds)\n",
    "sameWeight_mae = fonks.get_mae_score(y_test , sameWeight_preds)\n",
    "sameWeight_rmse = fonks.get_rmse_score(y_test , sameWeight_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Different Weight Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differentWeight_preds = np.round(cb_pred * 0.4 + lgb_pred * 0.1  + xgb_pred * 0.25 + gb_pred * 0.05 + rf_pred * 0.05 + svr_pred * 0.15)\n",
    "\n",
    "differentWeight_r2 = fonks.get_r2_score(y_test , differentWeight_preds)\n",
    "differentWeight_mae = fonks.get_mae_score(y_test , differentWeight_preds)\n",
    "differentWeight_rmse = fonks.get_rmse_score(y_test , differentWeight_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Ensemble Same Weight Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_sameWeight_preds = np.round((cb_pred + xgb_pred + svr_pred) / 3)\n",
    "\n",
    "simple_sameWeight_r2 = fonks.get_r2_score(y_test , simple_sameWeight_preds)\n",
    "simple_sameWeight_mae = fonks.get_mae_score(y_test , simple_sameWeight_preds)\n",
    "simple_sameWeight_rmse = fonks.get_rmse_score(y_test , simple_sameWeight_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Ensemble Different Weight Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_differentWeight_preds = np.round((cb_pred * 0.49 + xgb_pred * 0.35 + svr_pred * 0.16))\n",
    "\n",
    "simple_differentWeight_r2 = fonks.get_r2_score(y_test , simple_differentWeight_preds)\n",
    "simple_differentWeight_mae = fonks.get_mae_score(y_test , simple_differentWeight_preds)\n",
    "simple_differentWeight_rmse = fonks.get_rmse_score(y_test , simple_differentWeight_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame({\"Model\": [\"LinearRegression\", \"Ridge\", \"SVR\", \"DecisionTree\", \"RandomForest\", \"GradientBoosting\",\n",
    "                                 \"XGBoost\", \"LGBM\" , \"CatBoost\" , 'SameWeightModel' , 'DifferentWeightModel' , 'SimpleSameWeightModel' , 'SimpleDifferentWeightModel'],\n",
    "                        \"R2\": [lr_r2, rdg_r2, svr_r2, dt_r2, rf_r2 , gb_r2, xgb_r2, lgb_r2 , cb_r2 , sameWeight_r2 , differentWeight_r2 , simple_sameWeight_r2 , simple_differentWeight_r2 ],\n",
    "                        \"MAE\": [lr_mae, rdg_mae, svr_mae, dt_mae, rf_mae, gb_mae, xgb_mae, lgb_mae , cb_mae , sameWeight_mae , differentWeight_mae , simple_sameWeight_mae , simple_differentWeight_r2],\n",
    "                        \"RMSE\": [lr_rmse, rdg_rmse, svr_rmse, dt_rmse, rf_rmse, gb_rmse, xgb_rmse, lgb_rmse , cb_rmse , sameWeight_rmse , differentWeight_rmse , simple_sameWeight_rmse , simple_differentWeight_r2],\n",
    "                        })\n",
    "\n",
    "def labels(ax):\n",
    "    for p in ax.patches:\n",
    "        width = p.get_width()                        # get bar length\n",
    "        ax.text(width,                               # set the text at 1 unit right of the bar\n",
    "                p.get_y() + p.get_height() / 2,      # get Y coordinate + X coordinate / 2\n",
    "                '{:1.3f}'.format(width),             # set variable to display, 2 decimals\n",
    "                ha = 'left',                         # horizontal alignment\n",
    "                va = 'center')                       # vertical alignment\n",
    "    \n",
    "plt.figure(figsize=(14,10))\n",
    "plt.subplot(311)\n",
    "compare = compare.sort_values(by=\"R2\", ascending=False)\n",
    "ax=sns.barplot(x=\"R2\", y=\"Model\", data=compare, palette=\"Blues_d\")\n",
    "labels(ax)\n",
    "\n",
    "plt.subplot(312)\n",
    "compare = compare.sort_values(by=\"MAE\", ascending=True)\n",
    "ax=sns.barplot(x=\"MAE\", y=\"Model\", data=compare, palette=\"Blues_d\")\n",
    "labels(ax)\n",
    "\n",
    "plt.subplot(313)\n",
    "compare = compare.sort_values(by=\"RMSE\", ascending=True)\n",
    "ax=sns.barplot(x=\"RMSE\", y=\"Model\", data=compare, palette=\"Blues_d\")\n",
    "labels(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def pearson_compare(df1 , df2 , feature = 'Age'):\n",
    "    df1_values = df1[feature].values\n",
    "    df2_values = df2[feature].values\n",
    "    \n",
    "    # Pearson korelasyon katsayısı hesaplama\n",
    "    correlation, _ = pearsonr(df1_values, df2_values)\n",
    "    \n",
    "    print(f\"Pearson Korelasyon Katsayısı:\", correlation)\n",
    "    \n",
    " \n",
    "def jaccard_compare_preds(pred1, pred2):\n",
    "    # Jaccard benzerlik katsayısı hesaplama\n",
    "    jaccard_similarity = jaccard_score(pred1, pred2 , average='weighted')\n",
    "    \n",
    "    print(f\"Jaccard Benzerlik Katsayısı:\", jaccard_similarity)  \n",
    "    \n",
    "def jaccard_compare_dfs(df1 , df2 , feature = 'Age'):\n",
    "    df1_values = df1[feature].values\n",
    "    df2_values = df2[feature].values\n",
    "    \n",
    "    # Jaccard benzerlik katsayısı hesaplama\n",
    "    jaccard_similarity = jaccard_score(df1_values, df2_values , average='weighted')\n",
    "    \n",
    "    print(f\"Jaccard Benzerlik Katsayısı:\", jaccard_similarity)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_compare_preds(simple_differentWeight_preds , simple_sameWeight_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_compare_preds(simple_differentWeight_preds , differentWeight_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Age'] = simple_differentWeight_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
